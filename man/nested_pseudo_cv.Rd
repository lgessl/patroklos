% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nested_cv.R
\name{nested_pseudo_cv}
\alias{nested_pseudo_cv}
\title{Nested cross-validation for second-stage OOB predictions}
\usage{
nested_pseudo_cv(
  x,
  y,
  fitter1,
  fitter2,
  hyperparams1,
  hyperparams2,
  oob = c(FALSE, TRUE)
)
}
\arguments{
\item{x}{A numeric matrix holding the predictor features: rows are samples and
columns are features.}

\item{y}{A numeric vector holding the response variable.}

\item{fitter1}{A \emph{patroklos-compliant fitter with integrated CV} (for what this
means, see \code{\link[=ptk_zerosum]{ptk_zerosum()}}) to fit the early model.}

\item{fitter2}{A \emph{patroklos-compliant fitter with validated predictions} (
for what this means, see \code{\link[=ptk_ranger]{ptk_ranger()}}) to fit the late model.}

\item{hyperparams1}{A named list with hyperparaters we will pass to \code{fitter1}.}

\item{hyperparams2}{A named list with hyperparameters for the late model.
Unlike \code{hyperparams1}, we call \code{fitter2} for every combination of values in
\code{hyperparams2} and lambda value from \code{fitter1}.}

\item{oob}{A logical vector of length 2. If the first element is \code{TRUE}, train
the late model on out-of-bag, else cross-validated predictions from the early
model. If the second element is \code{TRUE}, evaluate the entire model on OOB,
else cross-validated predictions.}
}
\value{
An S3 object with class \code{nested_fit}, the model with the best
performance according to the out-of-bag (OOB) predictions based on cross-validated
predictions from the early model.
}
\description{
Perform a nested cross-validation for a late-integration scheme,
i.e., perform a cross-validation for the early model and then train second-stage
models on cross-validated predictions and evaluate the entire models via
out-of-bag (OOB) predictions of the second-stage models (usually a random
forest).
}
\details{
This function does hyperparameter tuning for a nested model, i.e.,
a so-called early model makes predictions from the high-dimensional part of
data (e.g. RNA-seq, Nanostring), we then provide these predictions as a
one-dimensional feature together with new features to a late model. Both the
early and late model try to predict \code{y}. To not provide the late model overly
optimistic (since overfitted) predictions during training, we feed its
training algorithm with values comparable to those we would observe for
independent test samples, i.e. either cross-validated or out-of-bage (OOB)
predictions. To evaluate the overall model, we do a second cross-validation
or use OOB predictions.

Note that the predictions we get for the nested model are not predictions as
one would observe for independent test samples:
Let's fix sample i. We get the OOB/CV prediction for sample i from models/
a model whose training algorithm didn't see sample i itself. But it probably
saw the prediction for a sample j != i according to an early model whose
training algorithm had seen sample i. Hence the term "pseudo" in the name of
this function. This heuristic saves a factor \code{n_folds} computation time
compared to a full nested cross-validation.
}
